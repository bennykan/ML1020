{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bennykan/ML1020/blob/master/Ml1020_Pretrained_Model_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c69DxfPUv00z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.version\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/ML1020/ML1020\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "z4Eu93PNytge",
    "outputId": "0c6726bb-43e9-442c-d1ad-784c66f73234"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/ML1020/ML1020/Sample\n",
      "Found 200 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = '/home/jupyter/ML1020/ML1020'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'Sample')\n",
    "print(train_dir)\n",
    "#validation_dir = os.path.join(base_dir, 'validation')\n",
    "#test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 10\n",
    "\n",
    "train_features = np.zeros(shape=(200, 15, 20, 512))\n",
    "train_labels = np.zeros(shape=(200,10))\n",
    " \n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(480, 640),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "id": "zcLWhSFg91rw",
    "outputId": "bc535b30-480c-4f60-f295-5c96ef1925ee"
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.0.0) /io/opencv/modules/imgproc/src/color.cpp:181: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-80139c7baa17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/train/c6/img_380.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mimg_cvt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_cvt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.0.0) /io/opencv/modules/imgproc/src/color.cpp:181: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread(base_dir + '/train/c6/img_380.jpg')\n",
    "img_cvt=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_cvt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "MoJLVH6WDo8e",
    "outputId": "ea22c8b3-66c5-42d4-d40f-b1a20d10fb10"
   },
   "outputs": [],
   "source": [
    "#Loading in Pretrained Model\n",
    "\n",
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(480, 640, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 782
    },
    "colab_type": "code",
    "id": "pGlhU7kzBMKy",
    "outputId": "b6f8028c-2857-4f85-ef17-4c7aacc66687"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 480, 640, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 480, 640, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 480, 640, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 240, 320, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 240, 320, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 240, 320, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 120, 160, 128)     0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 120, 160, 256)     295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 120, 160, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 120, 160, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 60, 80, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 60, 80, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 60, 80, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 60, 80, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 30, 40, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 30, 40, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 30, 40, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 30, 40, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 15, 20, 512)       0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6bWZjHse92N6",
    "outputId": "436969f4-f66d-4715-8a3f-8b9ddd207548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 15, 20, 512)\n"
     ]
    }
   ],
   "source": [
    "#Feature engineering\n",
    "\n",
    "i = 0\n",
    "for inputs_batch, labels_batch in train_generator:\n",
    "    features_batch = conv_base.predict(inputs_batch)\n",
    "    train_features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "    train_labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "    i += 1\n",
    "    if i * batch_size >= 200:\n",
    "        break\n",
    "print(train_features.shape)         \n",
    "train_features = np.reshape(train_features, (200, 15 * 20 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "Ik__UfMZApTl",
    "outputId": "00a35ea4-a540-4e7e-d480-e2fe05ed4120"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0.01537259 0.         0.         ... 0.         0.96648932 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.94795364 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.89855254 0.        ]\n",
      " ...\n",
      " [0.0930624  0.         0.         ... 0.         0.77023864 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.6494078  0.        ]\n",
      " [0.02176097 0.         0.         ... 0.         0.74609101 0.        ]]\n",
      "(200, 10)\n",
      "(200, 153600)\n"
     ]
    }
   ],
   "source": [
    "print(train_labels)\n",
    "print(train_features)\n",
    "print(train_labels.shape)\n",
    "print(train_features.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F7FUZjxlrhAD"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_features, train_labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "VjiYYtvaAqL1",
    "outputId": "5e745dd1-31b6-487f-9277-5162b68a8f98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         1.37048173 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.83549976 0.        ]\n",
      " [0.         0.         0.         ... 0.         1.01423395 0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.11735116 0.75239027 0.        ]\n",
      " [0.         0.         0.07238156 ... 0.         0.64992285 0.        ]\n",
      " [0.10070539 0.         0.         ... 0.01925092 0.94601667 0.        ]]\n",
      "(160, 153600)\n",
      "(40, 153600)\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "vX_p9cjrBqfh",
    "outputId": "580a8948-e273-4972-ce9f-5e171dcf8edc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 40 samples\n",
      "Epoch 1/7\n",
      "200/200 [==============================] - 8s 40ms/step - loss: 3.1790 - acc: 0.1100 - val_loss: 2.0182 - val_acc: 0.2000\n",
      "Epoch 2/7\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 2.1415 - acc: 0.2250 - val_loss: 1.7605 - val_acc: 0.6000\n",
      "Epoch 3/7\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.8888 - acc: 0.3700 - val_loss: 1.4971 - val_acc: 0.5750\n",
      "Epoch 4/7\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.7368 - acc: 0.4000 - val_loss: 1.2335 - val_acc: 0.8000\n",
      "Epoch 5/7\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.5478 - acc: 0.4750 - val_loss: 1.0344 - val_acc: 0.8250\n",
      "Epoch 6/7\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.3340 - acc: 0.5700 - val_loss: 0.8746 - val_acc: 0.9250\n",
      "Epoch 7/7\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.1440 - acc: 0.6950 - val_loss: 0.7399 - val_acc: 0.9250\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               39321856  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 39,324,426\n",
      "Trainable params: 39,324,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create NN to classifer 10 outputs\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "\n",
    "model.add(layers.Dense(256, activation='relu', input_dim=15 * 20 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs=7,\n",
    "                    batch_size=20,\n",
    "                   validation_data=(X_test,y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jzAL69FUyG_Q"
   },
   "source": [
    "Below is the list of testing labels and their descriptions\n",
    "\n",
    "\n",
    "\n",
    "*   c0: safe driving\n",
    "*   c1: texting - right\n",
    "*   c2: talking on the phone - right\n",
    "*   c3: texting - left\n",
    "*   c4: talking on the phone - left\n",
    "*   c5: operating the radio\n",
    "*   c6: drinking\n",
    "*   c7: reaching behind\n",
    "*   c8: hair and makeup\n",
    "*   c9: talking to passenger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_101.jpg  img_25136.jpg  img_41068.jpg  img_71188.jpg  img_97377.jpg\n",
      "img_11.jpg   img_31.jpg     img_49714.jpg  img_71233.jpg  img_97383.jpg\n",
      "img_165.jpg  img_326.jpg    img_58795.jpg  img_80278.jpg  img_97390.jpg\n",
      "img_227.jpg  img_39.jpg     img_71146.jpg  img_80282.jpg  img_97396.jpg\n"
     ]
    }
   ],
   "source": [
    "ls \"/home/jupyter/TEST data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1122
    },
    "colab_type": "code",
    "id": "_4nyoxxV5WQ8",
    "outputId": "89f80ea2-c4e7-498b-e5cc-59acea6ef4e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              img            c0            c1            c2            c3  \\\n",
      "0      img_31.jpg  6.669070e-29  2.709959e-10  5.295300e-09  1.228660e-10   \n",
      "1   img_80282.jpg  5.722410e-12  1.000000e+00  1.339381e-11  2.073463e-10   \n",
      "2   img_97377.jpg  5.508116e-14  2.656782e-07  2.291770e-04  8.108423e-10   \n",
      "3     img_227.jpg  3.153502e-26  9.310229e-18  5.727428e-17  4.122539e-04   \n",
      "4     img_326.jpg  5.130187e-05  2.091885e-22  3.792549e-10  5.329054e-03   \n",
      "5   img_97383.jpg  1.111705e-13  1.687699e-13  1.000000e+00  4.292856e-13   \n",
      "6   img_41068.jpg  3.394101e-04  1.779419e-08  7.977716e-02  1.221625e-05   \n",
      "7   img_71146.jpg  2.401002e-20  1.272794e-15  5.335541e-08  9.999999e-01   \n",
      "8   img_80278.jpg  1.161966e-21  5.781484e-10  8.476240e-10  1.466823e-08   \n",
      "9   img_25136.jpg  2.096712e-23  3.851835e-11  3.619238e-07  9.846943e-01   \n",
      "10     img_39.jpg  2.775348e-19  2.248719e-05  2.930307e-14  2.928659e-03   \n",
      "11  img_49714.jpg  6.980718e-08  9.365958e-01  5.764058e-02  5.734445e-04   \n",
      "12  img_71188.jpg  7.110400e-22  6.651200e-11  3.099477e-07  8.838199e-16   \n",
      "13  img_58795.jpg  5.412507e-13  3.021439e-13  3.900158e-12  3.220939e-10   \n",
      "14     img_11.jpg  5.348497e-19  4.180112e-01  6.012745e-07  3.806831e-10   \n",
      "15    img_165.jpg  1.117158e-24  2.529140e-19  4.358184e-15  1.766395e-05   \n",
      "16  img_71233.jpg  9.485098e-29  4.878287e-13  6.358476e-15  1.000000e+00   \n",
      "17  img_97396.jpg  1.127114e-13  2.320590e-08  1.734347e-03  1.622622e-06   \n",
      "18  img_97390.jpg  5.074174e-15  3.740935e-14  4.502498e-11  2.290234e-01   \n",
      "19    img_101.jpg  2.305800e-09  1.154787e-06  1.155540e-11  9.999757e-01   \n",
      "\n",
      "              c4            c5            c6            c7            c8  \\\n",
      "0   3.443566e-22  1.000000e+00  2.013154e-16  5.677133e-15  9.868798e-17   \n",
      "1   8.260995e-16  3.509045e-16  8.965806e-12  1.399783e-18  2.905346e-20   \n",
      "2   1.375460e-15  5.833157e-05  1.723302e-12  9.984198e-01  1.291765e-03   \n",
      "3   8.742723e-01  5.085412e-09  1.253154e-01  6.215361e-12  2.269746e-18   \n",
      "4   2.236379e-01  4.540645e-03  6.581977e-09  4.163205e-17  2.676355e-24   \n",
      "5   5.778180e-16  1.254826e-09  1.302733e-10  5.505288e-12  2.589719e-15   \n",
      "6   3.013547e-04  1.075359e-06  9.195340e-01  9.418940e-07  4.986805e-18   \n",
      "7   5.624171e-15  6.975576e-08  4.983022e-12  7.619607e-20  2.442447e-17   \n",
      "8   5.394556e-12  3.813612e-05  9.995235e-01  4.383302e-04  3.050019e-13   \n",
      "9   3.539848e-09  1.530496e-02  3.970802e-07  9.729960e-12  2.034732e-15   \n",
      "10  1.776186e-03  4.195881e-13  9.952727e-01  1.485175e-10  5.472493e-09   \n",
      "11  1.478268e-09  2.814493e-13  5.189958e-03  1.539523e-07  1.592515e-17   \n",
      "12  2.180909e-08  3.880044e-05  9.999608e-01  5.090279e-09  4.495412e-17   \n",
      "13  6.406684e-08  1.077367e-11  9.999583e-01  2.698055e-11  5.312791e-21   \n",
      "14  9.189795e-13  1.334938e-03  2.952919e-03  5.776542e-01  1.227030e-11   \n",
      "15  1.394678e-02  5.595072e-14  9.860356e-01  3.423388e-15  1.129981e-17   \n",
      "16  3.903700e-08  1.656705e-09  2.155614e-19  8.367765e-13  1.235558e-12   \n",
      "17  3.719666e-10  4.616554e-04  4.444249e-17  5.997481e-01  1.943543e-02   \n",
      "18  7.584920e-04  7.655131e-01  4.551751e-03  2.028092e-11  1.989349e-16   \n",
      "19  1.555310e-13  4.411103e-09  4.221407e-12  2.309553e-05  3.126902e-13   \n",
      "\n",
      "              c9  \n",
      "0   2.793686e-17  \n",
      "1   4.929908e-10  \n",
      "2   6.339790e-07  \n",
      "3   6.375448e-20  \n",
      "4   7.664411e-01  \n",
      "5   5.379287e-08  \n",
      "6   3.380490e-05  \n",
      "7   6.435762e-14  \n",
      "8   8.133216e-20  \n",
      "9   1.418618e-10  \n",
      "10  8.809655e-13  \n",
      "11  1.244941e-11  \n",
      "12  7.820575e-22  \n",
      "13  4.162296e-05  \n",
      "14  4.606980e-05  \n",
      "15  6.517677e-14  \n",
      "16  1.317857e-18  \n",
      "17  3.786188e-01  \n",
      "18  1.532115e-04  \n",
      "19  1.953916e-13  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "output_dir = '/home/jupyter/'\n",
    "test_base_dir = '/home/jupyter/TEST data/'\n",
    "prediction_list = []\n",
    "\n",
    "for file in glob.glob(test_base_dir + '*jpg'):\n",
    "  dirname, filename = os.path.split(file)\n",
    "  pred_row = [filename]\n",
    "  img = cv2.imread(file)\n",
    "  img_cvt=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  testimage = conv_base.predict(img_cvt.reshape(1,480,640,3))\n",
    "  testimage_rs = np.reshape(testimage, (1, 15 * 20 * 512))\n",
    "  pred = model.predict_proba(testimage_rs)\n",
    "  pred_list = pred[0].tolist()\n",
    "  pred_row = pred_row + pred_list\n",
    "  prediction_list.append(pred_row)\n",
    "\n",
    "df_results = pd.DataFrame(prediction_list,columns=['img','c0','c1','c2','c3','c4','c5','c6','c7','c8','c9'])\n",
    "df_results.to_csv(output_dir + 'sample_submission.csv',index=False)\n",
    "print(df_results)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Ml1020_Pretrained_Model_V2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
