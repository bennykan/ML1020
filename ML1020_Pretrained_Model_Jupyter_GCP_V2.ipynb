{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bennykan/ML1020/blob/master/Ml1020_Pretrained_Model_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===========================================================\n",
    "# ML1020 - Final Project: Mid-Term Proposal\n",
    "# Team Blue\n",
    "\n",
    "## Tyler Blakeley\n",
    "## Benjamin Kan\n",
    "## Avi Singh\n",
    "## Justin Kim\n",
    "\n",
    "\n",
    "# Distracted Driver Detection\n",
    "# ==========================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project is inspired by a past Kaggle competition hosted by State Farm, an insurance company based in the US.  Competition participants were invited to implement a machine learning algorithm to classify and predict the driverâ€™s behavior based on the images captured from the dashboard cameras installed in the vehicles (https://www.kaggle.com/c/state-farm-distracted-driver-detection/data). The host defined the following 10 driving behavior classifications\n",
    "\n",
    "| Label | Driver Behavior Descriptions |\n",
    "| ----- | ---------------------------- |\n",
    "| c0\t| normal driving\n",
    "| c1\t| texting - right\n",
    "| c2\t| talking on the phone - right\n",
    "| c3\t| texting - left\n",
    "| c4\t| talking on the phone - left\n",
    "| c5\t| operating the radio\n",
    "| c6\t| drinking\n",
    "| c7\t| reaching behind\n",
    "| c8\t| hair and makeup\n",
    "| c9\t| talking to passenger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Keras Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c69DxfPUv00z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.version\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/ML1020\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "id": "zcLWhSFg91rw",
    "outputId": "bc535b30-480c-4f60-f295-5c96ef1925ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "base_dir = '/home/jupyter/Data'\n",
    "img = cv2.imread(base_dir + '/train/c6/img_380.jpg')\n",
    "img_cvt=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_cvt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the VGG16 Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "MoJLVH6WDo8e",
    "outputId": "ea22c8b3-66c5-42d4-d40f-b1a20d10fb10"
   },
   "outputs": [],
   "source": [
    "#Loading in Pretrained Model\n",
    "\n",
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 782
    },
    "colab_type": "code",
    "id": "pGlhU7kzBMKy",
    "outputId": "b6f8028c-2857-4f85-ef17-4c7aacc66687"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding One Hidden Layer on Top of VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 16,814,666\n",
      "Trainable params: 16,814,666\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model with Conv Base Included\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#Set conv_base training weights to false so we dont re train the weights already learned\n",
    "print(len(model.trainable_weights))\n",
    "conv_base.trainable = False\n",
    "print(len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the Last Convolution Layer in VGG16 to be Re-Trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "print(len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data into Train and Validate Sets (80% Train % 20% Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17943 images belonging to 10 classes.\n",
      "Found 4481 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical',\n",
    "        subset=\"training\",\n",
    "        shuffle = True\n",
    "        )\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical',\n",
    "        subset=\"validation\",\n",
    "        shuffle = True\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=5,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,\n",
    "      #use_multiprocessing = True,\n",
    "      #workers = 4,\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jzAL69FUyG_Q"
   },
   "source": [
    "Below is the list of testing labels and their descriptions\n",
    "\n",
    "\n",
    "\n",
    "*   c0: safe driving\n",
    "*   c1: texting - right\n",
    "*   c2: talking on the phone - right\n",
    "*   c3: texting - left\n",
    "*   c4: talking on the phone - left\n",
    "*   c5: operating the radio\n",
    "*   c6: drinking\n",
    "*   c7: reaching behind\n",
    "*   c8: hair and makeup\n",
    "*   c9: talking to passenger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Code to run to save model \n",
    "model_json = model.to_json()\n",
    "with open(\"/home/jupyter/Saved_Models/model_50Epoch_1Train_1Hidden.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"/home/jupyter/Saved_Models/model_50Epoch_1Train_1Hidden.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Training and Validation Accuracy of 50 Epoch model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model V2\n",
    "\n",
    "## Add Second Hidden Layer and Re Train the last 2 layers of VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 16,814,666\n",
      "Trainable params: 9,179,402\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model with Conv Base Included\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "model_v2 = models.Sequential()\n",
    "model_v2.add(conv_base)\n",
    "model_v2.add(layers.Flatten())\n",
    "model_v2.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\n",
    "model_v2.add(layers.Dropout(0.5))\n",
    "model_v2.add(layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "\n",
    "model_v2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1' or layer.name == 'block4_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "print(len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " - 99s - loss: 2.4452 - acc: 0.1040 - val_loss: 2.2951 - val_acc: 0.1380\n",
      "Epoch 2/200\n",
      " - 75s - loss: 2.3405 - acc: 0.1275 - val_loss: 2.2405 - val_acc: 0.1730\n",
      "Epoch 3/200\n",
      " - 77s - loss: 2.2707 - acc: 0.1640 - val_loss: 2.1685 - val_acc: 0.2810\n",
      "Epoch 4/200\n",
      " - 79s - loss: 2.1621 - acc: 0.2260 - val_loss: 2.0382 - val_acc: 0.3220\n",
      "Epoch 5/200\n",
      " - 73s - loss: 2.0695 - acc: 0.2535 - val_loss: 1.8889 - val_acc: 0.3772\n",
      "Epoch 6/200\n",
      " - 67s - loss: 1.9518 - acc: 0.2905 - val_loss: 1.7448 - val_acc: 0.4430\n",
      "Epoch 7/200\n",
      " - 64s - loss: 1.8226 - acc: 0.3385 - val_loss: 1.7462 - val_acc: 0.3660\n",
      "Epoch 8/200\n",
      " - 65s - loss: 1.6790 - acc: 0.4130 - val_loss: 1.4767 - val_acc: 0.5180\n",
      "Epoch 9/200\n",
      " - 64s - loss: 1.5661 - acc: 0.4513 - val_loss: 1.3281 - val_acc: 0.5749\n",
      "Epoch 10/200\n",
      " - 27s - loss: 1.4739 - acc: 0.4800 - val_loss: 1.2707 - val_acc: 0.5870\n",
      "Epoch 11/200\n",
      " - 27s - loss: 1.3603 - acc: 0.5345 - val_loss: 1.1614 - val_acc: 0.6190\n",
      "Epoch 12/200\n",
      " - 27s - loss: 1.2238 - acc: 0.5840 - val_loss: 0.9965 - val_acc: 0.7040\n",
      "Epoch 13/200\n",
      " - 27s - loss: 1.2016 - acc: 0.5845 - val_loss: 1.0080 - val_acc: 0.6630\n",
      "Epoch 14/200\n",
      " - 27s - loss: 1.1497 - acc: 0.6160 - val_loss: 0.8624 - val_acc: 0.7319\n",
      "Epoch 15/200\n",
      " - 26s - loss: 1.0312 - acc: 0.6390 - val_loss: 0.8124 - val_acc: 0.7360\n",
      "Epoch 16/200\n",
      " - 27s - loss: 0.9896 - acc: 0.6640 - val_loss: 0.7782 - val_acc: 0.7540\n",
      "Epoch 17/200\n",
      " - 27s - loss: 0.8966 - acc: 0.7100 - val_loss: 0.7115 - val_acc: 0.7850\n",
      "Epoch 18/200\n",
      " - 27s - loss: 0.8524 - acc: 0.7134 - val_loss: 0.6071 - val_acc: 0.8124\n",
      "Epoch 19/200\n",
      " - 27s - loss: 0.7468 - acc: 0.7485 - val_loss: 0.6742 - val_acc: 0.7730\n",
      "Epoch 20/200\n",
      " - 27s - loss: 0.7296 - acc: 0.7720 - val_loss: 0.5383 - val_acc: 0.8310\n",
      "Epoch 21/200\n",
      " - 27s - loss: 0.7121 - acc: 0.7750 - val_loss: 0.5034 - val_acc: 0.8300\n",
      "Epoch 22/200\n",
      " - 27s - loss: 0.6518 - acc: 0.7855 - val_loss: 0.5271 - val_acc: 0.8310\n",
      "Epoch 23/200\n",
      " - 27s - loss: 0.6063 - acc: 0.8100 - val_loss: 0.4475 - val_acc: 0.8624\n",
      "Epoch 24/200\n",
      " - 27s - loss: 0.5761 - acc: 0.8225 - val_loss: 0.4259 - val_acc: 0.8570\n",
      "Epoch 25/200\n",
      " - 27s - loss: 0.5852 - acc: 0.8090 - val_loss: 0.4029 - val_acc: 0.8780\n",
      "Epoch 26/200\n",
      " - 27s - loss: 0.5681 - acc: 0.8090 - val_loss: 0.4067 - val_acc: 0.8770\n",
      "Epoch 27/200\n",
      " - 27s - loss: 0.5235 - acc: 0.8245 - val_loss: 0.3749 - val_acc: 0.8848\n",
      "Epoch 28/200\n",
      " - 27s - loss: 0.4884 - acc: 0.8485 - val_loss: 0.3040 - val_acc: 0.9040\n",
      "Epoch 29/200\n",
      " - 27s - loss: 0.4827 - acc: 0.8485 - val_loss: 0.3772 - val_acc: 0.8810\n",
      "Epoch 30/200\n",
      " - 27s - loss: 0.4413 - acc: 0.8615 - val_loss: 0.3823 - val_acc: 0.8810\n",
      "Epoch 31/200\n",
      " - 27s - loss: 0.4573 - acc: 0.8520 - val_loss: 0.3426 - val_acc: 0.8940\n",
      "Epoch 32/200\n",
      " - 27s - loss: 0.4399 - acc: 0.8635 - val_loss: 0.2916 - val_acc: 0.9134\n",
      "Epoch 33/200\n",
      " - 27s - loss: 0.4194 - acc: 0.8560 - val_loss: 0.3002 - val_acc: 0.9090\n",
      "Epoch 34/200\n",
      " - 27s - loss: 0.3752 - acc: 0.8845 - val_loss: 0.2733 - val_acc: 0.9200\n",
      "Epoch 35/200\n",
      " - 27s - loss: 0.3559 - acc: 0.8885 - val_loss: 0.2706 - val_acc: 0.9200\n",
      "Epoch 36/200\n",
      " - 27s - loss: 0.3368 - acc: 0.8955 - val_loss: 0.2771 - val_acc: 0.9174\n",
      "Epoch 37/200\n",
      " - 26s - loss: 0.3429 - acc: 0.8955 - val_loss: 0.2701 - val_acc: 0.9100\n",
      "Epoch 38/200\n",
      " - 27s - loss: 0.3600 - acc: 0.8880 - val_loss: 0.2047 - val_acc: 0.9490\n",
      "Epoch 39/200\n",
      " - 27s - loss: 0.3067 - acc: 0.8995 - val_loss: 0.2291 - val_acc: 0.9230\n",
      "Epoch 40/200\n",
      " - 27s - loss: 0.2957 - acc: 0.9080 - val_loss: 0.2003 - val_acc: 0.9380\n",
      "Epoch 41/200\n",
      " - 27s - loss: 0.2691 - acc: 0.9160 - val_loss: 0.2231 - val_acc: 0.9276\n",
      "Epoch 42/200\n",
      " - 27s - loss: 0.3060 - acc: 0.9010 - val_loss: 0.2059 - val_acc: 0.9420\n",
      "Epoch 43/200\n",
      " - 27s - loss: 0.2988 - acc: 0.9040 - val_loss: 0.1867 - val_acc: 0.9390\n",
      "Epoch 44/200\n",
      " - 27s - loss: 0.2927 - acc: 0.9045 - val_loss: 0.2476 - val_acc: 0.9240\n",
      "Epoch 45/200\n",
      " - 27s - loss: 0.2953 - acc: 0.9065 - val_loss: 0.2272 - val_acc: 0.9276\n",
      "Epoch 46/200\n",
      " - 27s - loss: 0.2540 - acc: 0.9255 - val_loss: 0.1913 - val_acc: 0.9380\n",
      "Epoch 47/200\n",
      " - 27s - loss: 0.2414 - acc: 0.9200 - val_loss: 0.2506 - val_acc: 0.9300\n",
      "Epoch 48/200\n",
      " - 27s - loss: 0.2793 - acc: 0.9200 - val_loss: 0.2112 - val_acc: 0.9300\n",
      "Epoch 49/200\n",
      " - 27s - loss: 0.2232 - acc: 0.9290 - val_loss: 0.1990 - val_acc: 0.9400\n",
      "Epoch 50/200\n",
      " - 27s - loss: 0.2300 - acc: 0.9265 - val_loss: 0.1966 - val_acc: 0.9429\n",
      "Epoch 51/200\n",
      " - 27s - loss: 0.2424 - acc: 0.9245 - val_loss: 0.1876 - val_acc: 0.9520\n",
      "Epoch 52/200\n",
      " - 27s - loss: 0.2242 - acc: 0.9335 - val_loss: 0.1774 - val_acc: 0.9480\n",
      "Epoch 53/200\n",
      " - 27s - loss: 0.2540 - acc: 0.9225 - val_loss: 0.1926 - val_acc: 0.9380\n",
      "Epoch 54/200\n",
      " - 27s - loss: 0.2250 - acc: 0.9280 - val_loss: 0.2118 - val_acc: 0.9256\n",
      "Epoch 55/200\n",
      " - 27s - loss: 0.2045 - acc: 0.9375 - val_loss: 0.1655 - val_acc: 0.9550\n",
      "Epoch 56/200\n",
      " - 27s - loss: 0.2026 - acc: 0.9365 - val_loss: 0.1830 - val_acc: 0.9240\n",
      "Epoch 57/200\n",
      " - 27s - loss: 0.2075 - acc: 0.9305 - val_loss: 0.2433 - val_acc: 0.9450\n",
      "Epoch 58/200\n",
      " - 27s - loss: 0.2011 - acc: 0.9370 - val_loss: 0.1887 - val_acc: 0.9350\n",
      "Epoch 59/200\n",
      " - 27s - loss: 0.2077 - acc: 0.9415 - val_loss: 0.1399 - val_acc: 0.9480\n",
      "Epoch 60/200\n",
      " - 27s - loss: 0.2000 - acc: 0.9420 - val_loss: 0.2084 - val_acc: 0.9350\n",
      "Epoch 61/200\n",
      " - 27s - loss: 0.1648 - acc: 0.9505 - val_loss: 0.1508 - val_acc: 0.9560\n",
      "Epoch 62/200\n",
      " - 27s - loss: 0.2048 - acc: 0.9415 - val_loss: 0.1788 - val_acc: 0.9430\n",
      "Epoch 63/200\n",
      " - 27s - loss: 0.1718 - acc: 0.9505 - val_loss: 0.1661 - val_acc: 0.9531\n",
      "Epoch 64/200\n",
      " - 27s - loss: 0.1962 - acc: 0.9430 - val_loss: 0.1296 - val_acc: 0.9590\n",
      "Epoch 65/200\n",
      " - 27s - loss: 0.1617 - acc: 0.9495 - val_loss: 0.1370 - val_acc: 0.9590\n",
      "Epoch 66/200\n",
      " - 27s - loss: 0.1664 - acc: 0.9485 - val_loss: 0.1333 - val_acc: 0.9590\n",
      "Epoch 67/200\n",
      " - 27s - loss: 0.1702 - acc: 0.9450 - val_loss: 0.1748 - val_acc: 0.9480\n",
      "Epoch 68/200\n",
      " - 27s - loss: 0.1699 - acc: 0.9540 - val_loss: 0.1015 - val_acc: 0.9674\n",
      "Epoch 69/200\n",
      " - 27s - loss: 0.1869 - acc: 0.9455 - val_loss: 0.1858 - val_acc: 0.9460\n",
      "Epoch 70/200\n",
      " - 27s - loss: 0.1661 - acc: 0.9495 - val_loss: 0.1453 - val_acc: 0.9570\n",
      "Epoch 71/200\n",
      " - 27s - loss: 0.1554 - acc: 0.9575 - val_loss: 0.1543 - val_acc: 0.9560\n",
      "Epoch 72/200\n",
      " - 26s - loss: 0.1764 - acc: 0.9485 - val_loss: 0.1332 - val_acc: 0.9602\n",
      "Epoch 73/200\n",
      " - 27s - loss: 0.1408 - acc: 0.9560 - val_loss: 0.1585 - val_acc: 0.9420\n",
      "Epoch 74/200\n",
      " - 27s - loss: 0.1515 - acc: 0.9550 - val_loss: 0.1356 - val_acc: 0.9600\n",
      "Epoch 75/200\n",
      " - 27s - loss: 0.1291 - acc: 0.9590 - val_loss: 0.1210 - val_acc: 0.9660\n",
      "Epoch 76/200\n",
      " - 27s - loss: 0.1347 - acc: 0.9605 - val_loss: 0.1074 - val_acc: 0.9670\n",
      "Epoch 77/200\n",
      " - 27s - loss: 0.1676 - acc: 0.9510 - val_loss: 0.1599 - val_acc: 0.9521\n",
      "Epoch 78/200\n",
      " - 27s - loss: 0.1313 - acc: 0.9570 - val_loss: 0.0903 - val_acc: 0.9700\n",
      "Epoch 79/200\n",
      " - 27s - loss: 0.1469 - acc: 0.9585 - val_loss: 0.1298 - val_acc: 0.9590\n",
      "Epoch 80/200\n",
      " - 27s - loss: 0.1506 - acc: 0.9495 - val_loss: 0.0646 - val_acc: 0.9840\n",
      "Epoch 81/200\n",
      " - 26s - loss: 0.1312 - acc: 0.9595 - val_loss: 0.1166 - val_acc: 0.9653\n",
      "Epoch 82/200\n",
      " - 27s - loss: 0.1304 - acc: 0.9635 - val_loss: 0.0980 - val_acc: 0.9720\n",
      "Epoch 83/200\n",
      " - 27s - loss: 0.1407 - acc: 0.9590 - val_loss: 0.1007 - val_acc: 0.9670\n",
      "Epoch 84/200\n",
      " - 27s - loss: 0.1397 - acc: 0.9610 - val_loss: 0.1159 - val_acc: 0.9600\n",
      "Epoch 85/200\n",
      " - 27s - loss: 0.1331 - acc: 0.9625 - val_loss: 0.1924 - val_acc: 0.9490\n",
      "Epoch 86/200\n",
      " - 27s - loss: 0.1489 - acc: 0.9570 - val_loss: 0.0828 - val_acc: 0.9817\n",
      "Epoch 87/200\n",
      " - 27s - loss: 0.1258 - acc: 0.9575 - val_loss: 0.1068 - val_acc: 0.9730\n",
      "Epoch 88/200\n",
      " - 27s - loss: 0.1129 - acc: 0.9610 - val_loss: 0.1063 - val_acc: 0.9700\n",
      "Epoch 89/200\n",
      " - 27s - loss: 0.1379 - acc: 0.9580 - val_loss: 0.1120 - val_acc: 0.9630\n",
      "Epoch 90/200\n",
      " - 27s - loss: 0.1382 - acc: 0.9675 - val_loss: 0.0996 - val_acc: 0.9715\n",
      "Epoch 91/200\n",
      " - 27s - loss: 0.1163 - acc: 0.9665 - val_loss: 0.1617 - val_acc: 0.9600\n",
      "Epoch 92/200\n",
      " - 27s - loss: 0.1170 - acc: 0.9650 - val_loss: 0.1120 - val_acc: 0.9650\n",
      "Epoch 93/200\n",
      " - 27s - loss: 0.1552 - acc: 0.9560 - val_loss: 0.0835 - val_acc: 0.9720\n",
      "Epoch 94/200\n",
      " - 27s - loss: 0.1125 - acc: 0.9700 - val_loss: 0.0674 - val_acc: 0.9870\n",
      "Epoch 95/200\n",
      " - 27s - loss: 0.1080 - acc: 0.9680 - val_loss: 0.2139 - val_acc: 0.9378\n",
      "Epoch 96/200\n",
      " - 27s - loss: 0.1315 - acc: 0.9600 - val_loss: 0.1250 - val_acc: 0.9600\n",
      "Epoch 97/200\n",
      " - 27s - loss: 0.1343 - acc: 0.9675 - val_loss: 0.2386 - val_acc: 0.9190\n",
      "Epoch 98/200\n",
      " - 27s - loss: 0.0972 - acc: 0.9710 - val_loss: 0.0625 - val_acc: 0.9800\n",
      "Epoch 99/200\n",
      " - 27s - loss: 0.1081 - acc: 0.9647 - val_loss: 0.1330 - val_acc: 0.9613\n",
      "Epoch 100/200\n",
      " - 27s - loss: 0.0972 - acc: 0.9675 - val_loss: 0.1467 - val_acc: 0.9660\n",
      "Epoch 101/200\n",
      " - 27s - loss: 0.1185 - acc: 0.9610 - val_loss: 0.0981 - val_acc: 0.9730\n",
      "Epoch 102/200\n",
      " - 27s - loss: 0.0997 - acc: 0.9690 - val_loss: 0.0598 - val_acc: 0.9810\n",
      "Epoch 103/200\n",
      " - 27s - loss: 0.1056 - acc: 0.9695 - val_loss: 0.1189 - val_acc: 0.9700\n",
      "Epoch 104/200\n",
      " - 26s - loss: 0.1221 - acc: 0.9665 - val_loss: 0.1522 - val_acc: 0.9613\n",
      "Epoch 105/200\n",
      " - 27s - loss: 0.1281 - acc: 0.9615 - val_loss: 0.0835 - val_acc: 0.9780\n",
      "Epoch 106/200\n",
      " - 27s - loss: 0.1173 - acc: 0.9695 - val_loss: 0.1074 - val_acc: 0.9700\n",
      "Epoch 107/200\n",
      " - 27s - loss: 0.0944 - acc: 0.9755 - val_loss: 0.1263 - val_acc: 0.9660\n",
      "Epoch 108/200\n",
      " - 27s - loss: 0.1038 - acc: 0.9690 - val_loss: 0.1087 - val_acc: 0.9704\n",
      "Epoch 109/200\n",
      " - 27s - loss: 0.1138 - acc: 0.9690 - val_loss: 0.1053 - val_acc: 0.9700\n",
      "Epoch 110/200\n",
      " - 27s - loss: 0.1218 - acc: 0.9655 - val_loss: 0.1410 - val_acc: 0.9630\n",
      "Epoch 111/200\n",
      " - 27s - loss: 0.0950 - acc: 0.9715 - val_loss: 0.0942 - val_acc: 0.9690\n",
      "Epoch 112/200\n",
      " - 27s - loss: 0.0927 - acc: 0.9725 - val_loss: 0.0670 - val_acc: 0.9830\n",
      "Epoch 113/200\n",
      " - 27s - loss: 0.0941 - acc: 0.9740 - val_loss: 0.0809 - val_acc: 0.9735\n",
      "Epoch 114/200\n",
      " - 27s - loss: 0.0813 - acc: 0.9735 - val_loss: 0.1543 - val_acc: 0.9620\n",
      "Epoch 115/200\n",
      " - 27s - loss: 0.0887 - acc: 0.9735 - val_loss: 0.1210 - val_acc: 0.9670\n",
      "Epoch 116/200\n",
      " - 27s - loss: 0.0947 - acc: 0.9735 - val_loss: 0.0687 - val_acc: 0.9800\n",
      "Epoch 117/200\n",
      " - 26s - loss: 0.0946 - acc: 0.9725 - val_loss: 0.0655 - val_acc: 0.9776\n",
      "Epoch 118/200\n",
      " - 27s - loss: 0.0867 - acc: 0.9770 - val_loss: 0.0914 - val_acc: 0.9730\n",
      "Epoch 119/200\n",
      " - 27s - loss: 0.0800 - acc: 0.9745 - val_loss: 0.0893 - val_acc: 0.9740\n",
      "Epoch 120/200\n",
      " - 27s - loss: 0.1032 - acc: 0.9705 - val_loss: 0.0799 - val_acc: 0.9750\n",
      "Epoch 121/200\n",
      " - 27s - loss: 0.0752 - acc: 0.9775 - val_loss: 0.0810 - val_acc: 0.9780\n",
      "Epoch 122/200\n",
      " - 27s - loss: 0.1086 - acc: 0.9685 - val_loss: 0.1183 - val_acc: 0.9653\n",
      "Epoch 123/200\n",
      " - 27s - loss: 0.1064 - acc: 0.9705 - val_loss: 0.0861 - val_acc: 0.9770\n",
      "Epoch 124/200\n",
      " - 27s - loss: 0.1132 - acc: 0.9705 - val_loss: 0.0932 - val_acc: 0.9720\n",
      "Epoch 125/200\n",
      " - 27s - loss: 0.0934 - acc: 0.9755 - val_loss: 0.0882 - val_acc: 0.9750\n",
      "Epoch 126/200\n",
      " - 27s - loss: 0.0974 - acc: 0.9760 - val_loss: 0.1223 - val_acc: 0.9704\n",
      "Epoch 127/200\n",
      " - 27s - loss: 0.0925 - acc: 0.9800 - val_loss: 0.0872 - val_acc: 0.9800\n",
      "Epoch 128/200\n",
      " - 27s - loss: 0.1050 - acc: 0.9705 - val_loss: 0.0788 - val_acc: 0.9740\n",
      "Epoch 129/200\n",
      " - 27s - loss: 0.0815 - acc: 0.9725 - val_loss: 0.1266 - val_acc: 0.9660\n",
      "Epoch 130/200\n",
      " - 27s - loss: 0.0903 - acc: 0.9750 - val_loss: 0.0582 - val_acc: 0.9810\n",
      "Epoch 131/200\n",
      " - 27s - loss: 0.0917 - acc: 0.9750 - val_loss: 0.0671 - val_acc: 0.9837\n",
      "Epoch 132/200\n",
      " - 27s - loss: 0.0928 - acc: 0.9740 - val_loss: 0.0922 - val_acc: 0.9750\n",
      "Epoch 134/200\n",
      " - 27s - loss: 0.0961 - acc: 0.9720 - val_loss: 0.0822 - val_acc: 0.9790\n",
      "Epoch 135/200\n",
      " - 27s - loss: 0.0794 - acc: 0.9770 - val_loss: 0.0472 - val_acc: 0.9888\n",
      "Epoch 136/200\n",
      " - 27s - loss: 0.0804 - acc: 0.9735 - val_loss: 0.1077 - val_acc: 0.9700\n",
      "Epoch 137/200\n",
      " - 27s - loss: 0.0733 - acc: 0.9815 - val_loss: 0.0441 - val_acc: 0.9870\n",
      "Epoch 138/200\n",
      " - 27s - loss: 0.0879 - acc: 0.9760 - val_loss: 0.0881 - val_acc: 0.9720\n",
      "Epoch 139/200\n",
      " - 27s - loss: 0.0842 - acc: 0.9755 - val_loss: 0.0833 - val_acc: 0.9710\n",
      "Epoch 140/200\n",
      " - 27s - loss: 0.0815 - acc: 0.9755 - val_loss: 0.0619 - val_acc: 0.9745\n",
      "Epoch 141/200\n",
      " - 27s - loss: 0.0792 - acc: 0.9800 - val_loss: 0.1089 - val_acc: 0.9590\n",
      "Epoch 142/200\n",
      " - 27s - loss: 0.1114 - acc: 0.9690 - val_loss: 0.0875 - val_acc: 0.9740\n",
      "Epoch 143/200\n",
      " - 27s - loss: 0.0957 - acc: 0.9745 - val_loss: 0.0583 - val_acc: 0.9810\n",
      "Epoch 144/200\n",
      " - 27s - loss: 0.0668 - acc: 0.9790 - val_loss: 0.1131 - val_acc: 0.9704\n",
      "Epoch 145/200\n",
      " - 27s - loss: 0.0789 - acc: 0.9795 - val_loss: 0.1066 - val_acc: 0.9670\n",
      "Epoch 146/200\n",
      " - 27s - loss: 0.0944 - acc: 0.9790 - val_loss: 0.1083 - val_acc: 0.9780\n",
      "Epoch 147/200\n",
      " - 27s - loss: 0.0785 - acc: 0.9805 - val_loss: 0.0659 - val_acc: 0.9780\n",
      "Epoch 148/200\n",
      " - 27s - loss: 0.0967 - acc: 0.9740 - val_loss: 0.0797 - val_acc: 0.9820\n",
      "Epoch 149/200\n",
      " - 26s - loss: 0.0871 - acc: 0.9730 - val_loss: 0.0883 - val_acc: 0.9755\n",
      "Epoch 150/200\n",
      " - 27s - loss: 0.0696 - acc: 0.9785 - val_loss: 0.0953 - val_acc: 0.9740\n",
      "Epoch 151/200\n",
      " - 27s - loss: 0.0892 - acc: 0.9760 - val_loss: 0.0866 - val_acc: 0.9780\n",
      "Epoch 152/200\n",
      " - 27s - loss: 0.0915 - acc: 0.9750 - val_loss: 0.0896 - val_acc: 0.9720\n",
      "Epoch 153/200\n",
      " - 27s - loss: 0.0557 - acc: 0.9845 - val_loss: 0.0737 - val_acc: 0.9786\n",
      "Epoch 154/200\n",
      " - 27s - loss: 0.0581 - acc: 0.9860 - val_loss: 0.2533 - val_acc: 0.9520\n",
      "Epoch 155/200\n",
      " - 27s - loss: 0.0826 - acc: 0.9795 - val_loss: 0.0947 - val_acc: 0.9670\n",
      "Epoch 156/200\n",
      " - 27s - loss: 0.0665 - acc: 0.9810 - val_loss: 0.0820 - val_acc: 0.9760\n",
      "Epoch 157/200\n",
      " - 27s - loss: 0.0943 - acc: 0.9740 - val_loss: 0.1168 - val_acc: 0.9620\n",
      "Epoch 158/200\n",
      " - 27s - loss: 0.0940 - acc: 0.9750 - val_loss: 0.0623 - val_acc: 0.9867\n",
      "Epoch 159/200\n",
      " - 27s - loss: 0.0673 - acc: 0.9795 - val_loss: 0.0882 - val_acc: 0.9820\n",
      "Epoch 160/200\n",
      " - 27s - loss: 0.1010 - acc: 0.9700 - val_loss: 0.0725 - val_acc: 0.9790\n",
      "Epoch 161/200\n",
      " - 27s - loss: 0.0875 - acc: 0.9770 - val_loss: 0.1470 - val_acc: 0.9630\n",
      "Epoch 162/200\n",
      " - 27s - loss: 0.0695 - acc: 0.9770 - val_loss: 0.1210 - val_acc: 0.9745\n",
      "Epoch 163/200\n",
      " - 27s - loss: 0.0907 - acc: 0.9760 - val_loss: 0.1046 - val_acc: 0.9650\n",
      "Epoch 164/200\n",
      " - 27s - loss: 0.0927 - acc: 0.9775 - val_loss: 0.1138 - val_acc: 0.9660\n",
      "Epoch 165/200\n",
      " - 27s - loss: 0.0670 - acc: 0.9790 - val_loss: 0.0784 - val_acc: 0.9820\n",
      "Epoch 166/200\n",
      " - 27s - loss: 0.0982 - acc: 0.9780 - val_loss: 0.1203 - val_acc: 0.9580\n",
      "Epoch 167/200\n",
      " - 27s - loss: 0.0704 - acc: 0.9805 - val_loss: 0.0502 - val_acc: 0.9878\n",
      "Epoch 168/200\n",
      " - 27s - loss: 0.0655 - acc: 0.9805 - val_loss: 0.0846 - val_acc: 0.9740\n",
      "Epoch 169/200\n",
      " - 27s - loss: 0.0854 - acc: 0.9790 - val_loss: 0.1351 - val_acc: 0.9640\n",
      "Epoch 170/200\n",
      " - 27s - loss: 0.0659 - acc: 0.9825 - val_loss: 0.1613 - val_acc: 0.9640\n",
      "Epoch 171/200\n",
      " - 26s - loss: 0.0746 - acc: 0.9810 - val_loss: 0.1045 - val_acc: 0.9735\n",
      "Epoch 172/200\n",
      " - 27s - loss: 0.0583 - acc: 0.9820 - val_loss: 0.0904 - val_acc: 0.9780\n",
      "Epoch 173/200\n",
      " - 27s - loss: 0.1101 - acc: 0.9780 - val_loss: 0.0794 - val_acc: 0.9820\n",
      "Epoch 174/200\n",
      " - 27s - loss: 0.0841 - acc: 0.9730 - val_loss: 0.0724 - val_acc: 0.9810\n",
      "Epoch 175/200\n",
      " - 27s - loss: 0.0786 - acc: 0.9760 - val_loss: 0.0924 - val_acc: 0.9740\n",
      "Epoch 176/200\n",
      " - 27s - loss: 0.0725 - acc: 0.9800 - val_loss: 0.1144 - val_acc: 0.9623\n",
      "Epoch 177/200\n",
      " - 27s - loss: 0.0921 - acc: 0.9755 - val_loss: 0.0920 - val_acc: 0.9810\n",
      "Epoch 178/200\n",
      " - 27s - loss: 0.0844 - acc: 0.9770 - val_loss: 0.0695 - val_acc: 0.9810\n",
      "Epoch 179/200\n",
      " - 27s - loss: 0.0589 - acc: 0.9840 - val_loss: 0.1253 - val_acc: 0.9710\n",
      "Epoch 180/200\n",
      " - 27s - loss: 0.0765 - acc: 0.9790 - val_loss: 0.0722 - val_acc: 0.9847\n",
      "Epoch 181/200\n",
      " - 27s - loss: 0.0806 - acc: 0.9805 - val_loss: 0.1044 - val_acc: 0.9670\n",
      "Epoch 182/200\n",
      " - 27s - loss: 0.0658 - acc: 0.9820 - val_loss: 0.1829 - val_acc: 0.9580\n",
      "Epoch 183/200\n",
      " - 27s - loss: 0.0889 - acc: 0.9735 - val_loss: 0.1146 - val_acc: 0.9730\n",
      "Epoch 184/200\n",
      " - 27s - loss: 0.0782 - acc: 0.9785 - val_loss: 0.0770 - val_acc: 0.9810\n",
      "Epoch 185/200\n",
      " - 27s - loss: 0.0788 - acc: 0.9795 - val_loss: 0.0625 - val_acc: 0.9817\n",
      "Epoch 186/200\n",
      " - 27s - loss: 0.0777 - acc: 0.9770 - val_loss: 0.0938 - val_acc: 0.9740\n",
      "Epoch 187/200\n",
      " - 27s - loss: 0.0839 - acc: 0.9755 - val_loss: 0.1015 - val_acc: 0.9790\n",
      "Epoch 188/200\n",
      " - 27s - loss: 0.0661 - acc: 0.9785 - val_loss: 0.0824 - val_acc: 0.9780\n",
      "Epoch 189/200\n",
      " - 26s - loss: 0.0923 - acc: 0.9755 - val_loss: 0.0627 - val_acc: 0.9755\n",
      "Epoch 190/200\n",
      " - 27s - loss: 0.0747 - acc: 0.9805 - val_loss: 0.1392 - val_acc: 0.9660\n",
      "Epoch 191/200\n",
      " - 26s - loss: 0.0500 - acc: 0.9830 - val_loss: 0.1087 - val_acc: 0.9760\n",
      "Epoch 192/200\n",
      " - 27s - loss: 0.0706 - acc: 0.9810 - val_loss: 0.0994 - val_acc: 0.9760\n",
      "Epoch 193/200\n",
      " - 27s - loss: 0.0614 - acc: 0.9850 - val_loss: 0.0983 - val_acc: 0.9720\n",
      "Epoch 194/200\n",
      " - 27s - loss: 0.0692 - acc: 0.9855 - val_loss: 0.0873 - val_acc: 0.9755\n",
      "Epoch 195/200\n",
      " - 27s - loss: 0.0595 - acc: 0.9860 - val_loss: 0.0684 - val_acc: 0.9790\n",
      "Epoch 196/200\n",
      " - 27s - loss: 0.0865 - acc: 0.9770 - val_loss: 0.0518 - val_acc: 0.9820\n",
      "Epoch 197/200\n",
      " - 27s - loss: 0.0802 - acc: 0.9760 - val_loss: 0.0638 - val_acc: 0.9830\n",
      "Epoch 198/200\n",
      " - 27s - loss: 0.0734 - acc: 0.9785 - val_loss: 0.1419 - val_acc: 0.9704\n",
      "Epoch 199/200\n",
      " - 27s - loss: 0.0833 - acc: 0.9835 - val_loss: 0.0583 - val_acc: 0.9880\n",
      "Epoch 200/200\n",
      " - 27s - loss: 0.0923 - acc: 0.9760 - val_loss: 0.0734 - val_acc: 0.9820\n"
     ]
    }
   ],
   "source": [
    "model_v2.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history_v2 = model_v2.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=200,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,\n",
    "      #use_multiprocessing = True,\n",
    "      #workers = 4,\n",
    "      verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "from keras import optimizers\n",
    "# Code to load json and create model\n",
    "json_file = open('/home/jupyter/Saved_Models/model_v3.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"/home/jupyter/Saved_Models/model_v3.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "loaded_model.compile(optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model_v2.to_json()\n",
    "with open(\"/home/jupyter/Saved_Models/model_200epoch_2CNN.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_v2.save_weights(\"/home/jupyter/Saved_Models/model_200epoch_2CNN.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#test data\n",
    "base_dir = '/home/jupyter/Data'\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        '/home/jupyter/Data/TEST',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        classes=['test'],  # only data, no labels\n",
    "        shuffle=False\n",
    "       )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "probabilities = loaded_model.predict_generator(test_generator, 79727,verbose=1)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/home/jupyter/Submission/'\n",
    "import pandas as pd\n",
    "df_prob = pd.DataFrame(probabilities)\n",
    "df_label = pd.DataFrame(test_generator.filenames[0:79727])\n",
    "df = pd.concat([df_label,df_prob],axis=1)\n",
    "df.columns = ['img','c0','c1','c2','c3','c4','c5','c6','c7','c8','c9']\n",
    "df.head()\n",
    "df.to_csv(output_dir + 'sample_submission2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(probabilities)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Ml1020_Pretrained_Model_V2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
